%{
#include "amd64/amd64.h"
#include "op.h"

#define YY_INPUT(ctx, buf, result, max_size)   \
{                                              \
    char yyc = ctx->op->text[ctx->idx];        \
    ctx->idx += yyc != 0;                      \
    result = yyc == 0 ? 0 : (*(buf) = yyc, 1); \
}                                              \
%}

Top = Branch | BranchMem | BranchMemSafe | CallInd | CallIndMem | CallIndMemSafe | Call | Ret

# we use r15 here so that we get consistent instruction sizes, so that the nop
# has the correct size to align the call to the end of the bundle. In theory,
# we could make two CallInds -- one for registers that require a REX prefix and
# one for ones that don't.
CallInd = 'call' 'q'? - '*' r:XREG {
    mkinsn("movq %s, %%r15", r.val);
    mkdirective(bundle_align());
    mkdirective(".bundle_lock");
    bundle_mask("%r15");
    bundle_nop_indcall();
    mkinsn("callq *%%r15");
    mkdirective(".bundle_unlock");
    mkdirective(bundle_align());
    rfree(r);
}

CallIndMem = 'call' 'q'? - '*' a:Addr {
    if (args.boxtype < BOX_FULL) {
        mkinsn("movq %s, %%r15", a.unmod);
    } else {
        mkguards(a);
        mkinsn("movq %s, %%r15", a.val);
        mkpost(a);
    }
    mkdirective(bundle_align());
    mkdirective(".bundle_lock");
    bundle_mask("%r15");
    bundle_nop_indcall();
    mkinsn("callq *%%r15");
    mkdirective(".bundle_unlock");
    mkdirective(bundle_align());
    rfree(a);
}

CallIndMemSafe = 'call' 'q'? - '*' a:Addr {
    mkinsn("movq %s, %%r15", a.unmod);
    mkdirective(bundle_align());
    mkdirective(".bundle_lock");
    bundle_mask("%r15");
    bundle_nop_indcall();
    mkinsn("callq *%%r15");
    mkdirective(".bundle_unlock");
    mkdirective(bundle_align());
    rfree(a);
}

Call = 'call' 'q'? - rest:ITEM {
    if (!args.padcall)
        mkdirective(bundle_align());
    bundle_nop_call();
    mkinsn("callq %s", rest.val);
    mkdirective(bundle_align());
    rfree(rest);
}

BranchMem = j:JMP - '*' a:Addr {
    if (args.boxtype < BOX_FULL) {
        mkinsn("movq %s, %%r15", a.unmod);
    } else {
        mkguards(a);
        mkinsn("movq %s, %%r15", a.val);
        mkpost(a);
    }
    mkdirective(".bundle_lock");
    bundle_mask("%r15");
    mkinsn("%s *%%r15", j.val);
    mkdirective(".bundle_unlock");
    rfree(j); rfree(a);
}

BranchMemSafe = j:JMP - '*' a:Addr {
    mkinsn("movq %s, %%r15", a.unmod);
    mkdirective(".bundle_lock");
    bundle_mask("%r15");
    mkinsn("%s *%%r15", j.val);
    mkdirective(".bundle_unlock");
    rfree(j); rfree(a);
}

Branch = j:JMP '*' r:XREG {
    mkdirective(".bundle_lock");
    bundle_mask(r.val);
    mkinsn("%s *%s", j.val, r.val);
    mkdirective(".bundle_unlock");
    rfree(j); rfree(r);
}

JMP = < 'notrack'? - 'jmp' 'q'? > - {
    $$ = (Result) { .val = strndup(yytext, yyleng) }
}

Ret = 'ret' 'q'? - {
    if (args.singlethread && args.boxtype <= BOX_BUNDLEJUMPS) {
        mkdirective(".bundle_lock");
        mkinsn("andq $0xffffffff%s, (%rsp)", bundle_mask_constant());
        mkinsn("ret");
        mkdirective(".bundle_unlock");
    } else {
        mkinsn("popq %%r15");
        mkdirective(".bundle_lock");
        bundle_mask("%r15");
        mkinsn("jmpq *%%r15");
        mkdirective(".bundle_unlock");
    }
}

%%

void
amd64_branchpass(struct op* op)
{
    if (!op->insn)
        return;
    yycontext ctx;
    memset(&ctx, 0, sizeof(yycontext));
    ctx.op = op;
    oplocate(op);
    if (yyparse(&ctx)) {
        opremove(op);
        opfree(op);
    }
    yyrelease(&ctx);
}
